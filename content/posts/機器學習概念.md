---
title: "機器學習概念"
date: 2021-06-29
draft: true
categories: 
- Machine Learning
tags:
- ML
- Python
---

### 統計複習：

**標準差**：資料量的分散程度，愈大代表資料愈離散

**變異係數**：當兩種不同的資料要比較時如身高、體重，因為因為兩者資料類別不同無法直接比較標準差，需要使用變異係數才可比較，因此可以將該數值的標準差/該數的平均數，所算出來的變異係數，即可直接比較體重和身高的散布程度。

**常態分佈：**一個資料群的數值越多越接近常態分佈

## **監督式學習：**

### Regression (回歸演算法

- **linear regression**

    -Simple linear regression (簡單線性回歸

    -Multiple linear regression (多重線性迴歸

- **Polynomial regression (多項式回歸**

### **Classification** (分類演算法

- **KNN - Nearest Neighbor Classification (最近鄰居分類法**
- **GaussianNB (高斯貝氏分類器**

    Naive Bayes Classification (貝氏分類器

- **SVM - Support Vector Machine (支援向量機**

- 資料處理補充

    ＊資料處理

    正規化處理 - 避免有偏值降低整體準確度

    **特徵標準化**

    ```python
    sc = StandardScaler()
    sc.fit(x_train)
    x_train_std = sc.transform(x_train)
    x_test_std = sc.transform(x_test)
    ```

    ＊文字的資料處理

    - onehot：無權重概念 ex 男性 vs 女性
    - label：若有權重概念可用 ex 房價-台北市 vs 新北市，權重較高

    ＊空值的資料處理

    - df.dropna()
    - df.fillna()
    - KNN 演算法做分類

    - df.isnull()
    - df.notnull()
    - df.info()

### Decision tree

精準度高但容易不全面

**Information Gain (資訊獲利)**

- Entropy(熵)

    Entropy = −𝑝 ∗ 𝑙𝑜𝑔2𝑝 − 𝑞 ∗ 𝑙𝑜𝑔2𝑞

    p:成功的機率(或true的機率) q:失敗的機率(或false的機率)

- Gini Index (吉尼係數)

    Gini 係數公式為 𝑝2 + 𝑞2

### Random  forest

不一定會Decision tree  好但比面向比較廣

Random Forest 概念：

＊結合多顆CART樹(CART樹為使用 GINI算法 ****的決策樹)

＊加入隨機分配的訓練資料，以大幅增進最終的運算結果

＊由許多不同的決策樹所組成的一個學習器

＊結合多個「弱學習器」來建構一個更強的模型:「強學習器」

＊整體(集成)機器學習(Ensemble Method) 

要形成多顆具差異性的樹以進行Ensemble Method，必須先將訓練樣本進行分化，才能產生多顆具差異性的CART樹，其作法有兩種方式

- Bagging(Bootstrap Aggregation)
- Boosting

**Random Forest = Bagging + Decision Tree**

Random Forest 步驟：

定義大小為n的隨機樣本(這裡指的是用bagging方法)，就是從資料集中隨機選取n個資料，取完後放回。

從選取的n個資料中，訓練出決策樹。對每一個節點:
a. 隨機選取d個特徵(假設總共有M個特徵,d<<M)
b. 使用特徵分割該節點(信息增益，information gain)

重複k次以上兩個步驟
匯總所有決策樹的預測，以多數決的方式，來決定分類結果。

### Extreme Gradient Boosting (XGBoost

目標函數 = 損失函數 + 正則項

## **非監督式學習：**

### **Cluster Analysis** (聚類

- **K-means**

    -elbow method (手肘法

    -Silhouette Coefficient (輪廓係數法

- **Gaussian Mixture Models GMMs (高斯混合模型**
- **Mean Shift (聚類算法**
- **Hierarchical clustering (階層式分群**

    -Bottom-up, agglomerative / agglomerative hierarchical clustering / AGNES - AGglomerative NESTing (聚合式階層分群法

    -Top-down, divisible / DIANA - DIvisive ANAlysis (分裂式階層分群法 

- **Affinity matrix (鄰接矩陣**

### **Dimension Reduction** (降維

**Linear, global structure preserved**

- PCA - Principle component analysis (主成分分析
- LDA - Linear Discriminant Analysis / Fisher Linear Discriminant (線性區別分析/Fisher分類器/Fisher線性判別
- 

**Non-linear, global structure preserved**

- MDS- MultiDimensional Scaling (多維尺度變換
- ISOMAP - Isometric Mapping (等距特徵映射

**Non-linear, local structure preserved**

- LLE
- LE
- t-SNE

- SVD - Singular value decomposition (奇異值分解體

    補充：SVD的用處有很多，比如:LSA(隱性語義分析)、推薦系統、特徵壓縮(或稱資料降維)

- Manifold Surface (抽象曲面
- AutoEncoder (自編碼器

參考資料：[https://medium.com/marketingdatascience/機器學習演算法-監督與非監督式學習-e9dbeee94a30](https://medium.com/marketingdatascience/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95-%E7%9B%A3%E7%9D%A3%E8%88%87%E9%9D%9E%E7%9B%A3%E7%9D%A3%E5%BC%8F%E5%AD%B8%E7%BF%92-e9dbeee94a30)